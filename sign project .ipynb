{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37fa36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8df060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12931 images belonging to 37 classes.\n",
      "Found 5541 images belonging to 37 classes.\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'I LOVE YOU', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "img_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                            #rotation_range=90,\n",
    "                            brightness_range=(0.5,1), \n",
    "                            #shear_range=0.2, \n",
    "                            #zoom_range=0.2,\n",
    "                            channel_shift_range=0.2,\n",
    "                            #horizontal_flip=True,\n",
    "                            #vertical_flip=True,\n",
    "                            rescale=1./255,\n",
    "                            validation_split=0.3)\n",
    "root_dir = 'D:\\Sign Project\\hand-gesture-recognition-main\\DATASET'\n",
    "\n",
    "img_generator_flow_train = img_generator.flow_from_directory(\n",
    "    directory=root_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    subset=\"training\")\n",
    "\n",
    "img_generator_flow_valid = img_generator.flow_from_directory(\n",
    "    directory=root_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    subset=\"validation\")  \n",
    "data_dir = 'D:\\Sign Project\\hand-gesture-recognition-main\\DATASET'\n",
    "Names0 = os.listdir(data_dir)\n",
    "Names=sorted(Names0)\n",
    "print(Names)\n",
    "print(len(Names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2903d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 11s 0us/step\n",
      "87924736/87910968 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(input_shape=(224,224,3),\n",
    "                                               include_top=False,\n",
    "                                               weights = \"imagenet\"\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04729c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88324bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(len(Names), activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec92e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 2048)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 37)                303141    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,105,925\n",
      "Trainable params: 303,141\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e075e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics = [tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a2750b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "16/16 [==============================] - 249s 16s/step - loss: 5.1654 - categorical_accuracy: 0.4844 - val_loss: 1.0377 - val_categorical_accuracy: 0.7935\n",
      "Epoch 2/64\n",
      "16/16 [==============================] - 299s 20s/step - loss: 0.5252 - categorical_accuracy: 0.8828 - val_loss: 0.4831 - val_categorical_accuracy: 0.8962\n",
      "Epoch 3/64\n",
      "16/16 [==============================] - 271s 18s/step - loss: 0.2475 - categorical_accuracy: 0.9375 - val_loss: 0.5467 - val_categorical_accuracy: 0.9051\n",
      "Epoch 4/64\n",
      "16/16 [==============================] - 304s 20s/step - loss: 0.1307 - categorical_accuracy: 0.9668 - val_loss: 0.1983 - val_categorical_accuracy: 0.9592\n",
      "Epoch 5/64\n",
      "16/16 [==============================] - 395s 26s/step - loss: 0.0442 - categorical_accuracy: 0.9824 - val_loss: 0.1844 - val_categorical_accuracy: 0.9616\n",
      "Epoch 6/64\n",
      "16/16 [==============================] - 263s 17s/step - loss: 0.0396 - categorical_accuracy: 0.9805 - val_loss: 0.1447 - val_categorical_accuracy: 0.9718\n",
      "Epoch 7/64\n",
      "16/16 [==============================] - 235s 16s/step - loss: 0.0407 - categorical_accuracy: 0.9883 - val_loss: 0.0992 - val_categorical_accuracy: 0.9760\n",
      "Epoch 8/64\n",
      "16/16 [==============================] - 202s 13s/step - loss: 0.0565 - categorical_accuracy: 0.9863 - val_loss: 0.1314 - val_categorical_accuracy: 0.9727\n",
      "Epoch 9/64\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.0543 - categorical_accuracy: 0.9834 - val_loss: 0.1861 - val_categorical_accuracy: 0.9664\n",
      "Epoch 10/64\n",
      "16/16 [==============================] - 218s 14s/step - loss: 0.0103 - categorical_accuracy: 0.9961 - val_loss: 0.0877 - val_categorical_accuracy: 0.9780\n",
      "Epoch 11/64\n",
      "16/16 [==============================] - 237s 16s/step - loss: 0.0477 - categorical_accuracy: 0.9883 - val_loss: 0.2067 - val_categorical_accuracy: 0.9632\n",
      "Epoch 12/64\n",
      "16/16 [==============================] - 282s 19s/step - loss: 0.0499 - categorical_accuracy: 0.9824 - val_loss: 0.1673 - val_categorical_accuracy: 0.9664\n",
      "Epoch 13/64\n",
      "16/16 [==============================] - 312s 21s/step - loss: 0.0333 - categorical_accuracy: 0.9883 - val_loss: 0.4346 - val_categorical_accuracy: 0.9381\n",
      "Epoch 14/64\n",
      "16/16 [==============================] - 367s 24s/step - loss: 0.1912 - categorical_accuracy: 0.9785 - val_loss: 0.2243 - val_categorical_accuracy: 0.9484\n",
      "Epoch 15/64\n",
      "16/16 [==============================] - 374s 25s/step - loss: 0.0480 - categorical_accuracy: 0.9883 - val_loss: 0.3497 - val_categorical_accuracy: 0.9327\n",
      "Epoch 16/64\n",
      "16/16 [==============================] - 350s 23s/step - loss: 0.0672 - categorical_accuracy: 0.9785 - val_loss: 0.2434 - val_categorical_accuracy: 0.9567\n",
      "Epoch 17/64\n",
      "16/16 [==============================] - 364s 24s/step - loss: 0.0829 - categorical_accuracy: 0.9805 - val_loss: 0.0785 - val_categorical_accuracy: 0.9807\n",
      "Epoch 18/64\n",
      "16/16 [==============================] - 367s 24s/step - loss: 0.1154 - categorical_accuracy: 0.9746 - val_loss: 0.3223 - val_categorical_accuracy: 0.9594\n",
      "Epoch 19/64\n",
      "16/16 [==============================] - 303s 20s/step - loss: 0.1355 - categorical_accuracy: 0.9766 - val_loss: 0.1818 - val_categorical_accuracy: 0.9684\n",
      "Epoch 20/64\n",
      "16/16 [==============================] - 367s 24s/step - loss: 0.0486 - categorical_accuracy: 0.9834 - val_loss: 0.2384 - val_categorical_accuracy: 0.9632\n",
      "Epoch 21/64\n",
      "16/16 [==============================] - 360s 24s/step - loss: 0.0663 - categorical_accuracy: 0.9863 - val_loss: 0.1100 - val_categorical_accuracy: 0.9834\n",
      "Epoch 22/64\n",
      "16/16 [==============================] - 388s 26s/step - loss: 0.0449 - categorical_accuracy: 0.9883 - val_loss: 0.1808 - val_categorical_accuracy: 0.9717\n",
      "Epoch 23/64\n",
      "16/16 [==============================] - 370s 24s/step - loss: 0.0590 - categorical_accuracy: 0.9902 - val_loss: 0.0676 - val_categorical_accuracy: 0.9861\n",
      "Epoch 24/64\n",
      "16/16 [==============================] - 352s 23s/step - loss: 0.0325 - categorical_accuracy: 0.9902 - val_loss: 0.1082 - val_categorical_accuracy: 0.9803\n",
      "Epoch 25/64\n",
      "16/16 [==============================] - 347s 23s/step - loss: 0.0084 - categorical_accuracy: 0.9961 - val_loss: 0.1860 - val_categorical_accuracy: 0.9682\n",
      "Epoch 26/64\n",
      "16/16 [==============================] - 306s 20s/step - loss: 0.0695 - categorical_accuracy: 0.9863 - val_loss: 0.1820 - val_categorical_accuracy: 0.9738\n",
      "Epoch 27/64\n",
      "16/16 [==============================] - 321s 21s/step - loss: 0.0555 - categorical_accuracy: 0.9922 - val_loss: 0.1471 - val_categorical_accuracy: 0.9762\n",
      "Epoch 28/64\n",
      "16/16 [==============================] - 335s 22s/step - loss: 0.0350 - categorical_accuracy: 0.9863 - val_loss: 0.1602 - val_categorical_accuracy: 0.9722\n",
      "Epoch 29/64\n",
      "16/16 [==============================] - 314s 21s/step - loss: 0.0412 - categorical_accuracy: 0.9883 - val_loss: 0.1403 - val_categorical_accuracy: 0.9782\n",
      "Epoch 30/64\n",
      "16/16 [==============================] - 282s 19s/step - loss: 0.0447 - categorical_accuracy: 0.9922 - val_loss: 0.1487 - val_categorical_accuracy: 0.9778\n",
      "Epoch 31/64\n",
      "16/16 [==============================] - 207s 14s/step - loss: 0.0303 - categorical_accuracy: 0.9961 - val_loss: 0.2110 - val_categorical_accuracy: 0.9644\n",
      "Epoch 32/64\n",
      "16/16 [==============================] - 219s 14s/step - loss: 0.0542 - categorical_accuracy: 0.9844 - val_loss: 0.1241 - val_categorical_accuracy: 0.9783\n",
      "Epoch 33/64\n",
      "16/16 [==============================] - 235s 16s/step - loss: 0.0781 - categorical_accuracy: 0.9805 - val_loss: 0.2290 - val_categorical_accuracy: 0.9598\n",
      "Epoch 34/64\n",
      "16/16 [==============================] - 266s 18s/step - loss: 0.0308 - categorical_accuracy: 0.9863 - val_loss: 0.2797 - val_categorical_accuracy: 0.9697\n",
      "Epoch 35/64\n",
      "16/16 [==============================] - 310s 21s/step - loss: 0.0314 - categorical_accuracy: 0.9941 - val_loss: 0.2469 - val_categorical_accuracy: 0.9659\n",
      "Epoch 36/64\n",
      "16/16 [==============================] - 280s 19s/step - loss: 0.0658 - categorical_accuracy: 0.9902 - val_loss: 0.1222 - val_categorical_accuracy: 0.9798\n",
      "Epoch 37/64\n",
      "16/16 [==============================] - 330s 22s/step - loss: 0.0505 - categorical_accuracy: 0.9863 - val_loss: 0.2129 - val_categorical_accuracy: 0.9664\n",
      "Epoch 38/64\n",
      "16/16 [==============================] - 301s 20s/step - loss: 0.2290 - categorical_accuracy: 0.9824 - val_loss: 0.6612 - val_categorical_accuracy: 0.9294\n",
      "Epoch 39/64\n",
      "16/16 [==============================] - 289s 19s/step - loss: 0.3035 - categorical_accuracy: 0.9492 - val_loss: 0.4923 - val_categorical_accuracy: 0.9579\n",
      "Epoch 40/64\n",
      "16/16 [==============================] - 287s 19s/step - loss: 0.0763 - categorical_accuracy: 0.9834 - val_loss: 0.2444 - val_categorical_accuracy: 0.9599\n",
      "Epoch 41/64\n",
      "16/16 [==============================] - 285s 19s/step - loss: 0.0481 - categorical_accuracy: 0.9922 - val_loss: 0.2484 - val_categorical_accuracy: 0.9706\n",
      "Epoch 42/64\n",
      "16/16 [==============================] - 292s 19s/step - loss: 0.0358 - categorical_accuracy: 0.9941 - val_loss: 0.2147 - val_categorical_accuracy: 0.9767\n",
      "Epoch 43/64\n",
      "16/16 [==============================] - 285s 19s/step - loss: 0.0149 - categorical_accuracy: 0.9941 - val_loss: 0.1961 - val_categorical_accuracy: 0.9785\n",
      "Epoch 44/64\n",
      "16/16 [==============================] - 287s 19s/step - loss: 0.0461 - categorical_accuracy: 0.9941 - val_loss: 0.1917 - val_categorical_accuracy: 0.9778\n",
      "Epoch 45/64\n",
      "16/16 [==============================] - 285s 19s/step - loss: 0.0236 - categorical_accuracy: 0.9941 - val_loss: 0.2497 - val_categorical_accuracy: 0.9731\n",
      "Epoch 46/64\n",
      "16/16 [==============================] - 283s 19s/step - loss: 0.0151 - categorical_accuracy: 0.9961 - val_loss: 0.4118 - val_categorical_accuracy: 0.9437\n",
      "Epoch 47/64\n",
      "16/16 [==============================] - 288s 19s/step - loss: 0.1344 - categorical_accuracy: 0.9805 - val_loss: 0.3060 - val_categorical_accuracy: 0.9574\n",
      "Epoch 48/64\n",
      "16/16 [==============================] - 249s 16s/step - loss: 0.0895 - categorical_accuracy: 0.9844 - val_loss: 0.1953 - val_categorical_accuracy: 0.9744\n",
      "Epoch 49/64\n",
      "16/16 [==============================] - 248s 16s/step - loss: 0.0406 - categorical_accuracy: 0.9902 - val_loss: 0.7412 - val_categorical_accuracy: 0.9487\n",
      "Epoch 50/64\n",
      "16/16 [==============================] - 219s 14s/step - loss: 0.0633 - categorical_accuracy: 0.9902 - val_loss: 0.3578 - val_categorical_accuracy: 0.9596\n",
      "Epoch 51/64\n",
      "16/16 [==============================] - 210s 14s/step - loss: 0.0433 - categorical_accuracy: 0.9941 - val_loss: 0.3955 - val_categorical_accuracy: 0.9565\n",
      "Epoch 52/64\n",
      "16/16 [==============================] - 256s 17s/step - loss: 0.0045 - categorical_accuracy: 0.9980 - val_loss: 0.3456 - val_categorical_accuracy: 0.9561\n",
      "Epoch 53/64\n",
      "16/16 [==============================] - 343s 23s/step - loss: 0.0063 - categorical_accuracy: 0.9961 - val_loss: 0.2594 - val_categorical_accuracy: 0.9686\n",
      "Epoch 54/64\n",
      "16/16 [==============================] - 400s 27s/step - loss: 0.0128 - categorical_accuracy: 0.9961 - val_loss: 0.2785 - val_categorical_accuracy: 0.9672\n",
      "Epoch 55/64\n",
      "16/16 [==============================] - 393s 26s/step - loss: 0.0512 - categorical_accuracy: 0.9941 - val_loss: 0.6428 - val_categorical_accuracy: 0.9527\n",
      "Epoch 56/64\n",
      "16/16 [==============================] - 309s 20s/step - loss: 0.0991 - categorical_accuracy: 0.9941 - val_loss: 0.3136 - val_categorical_accuracy: 0.9574\n",
      "Epoch 57/64\n",
      "16/16 [==============================] - 327s 22s/step - loss: 0.0586 - categorical_accuracy: 0.9902 - val_loss: 0.3543 - val_categorical_accuracy: 0.9502\n",
      "Epoch 58/64\n",
      "16/16 [==============================] - 330s 22s/step - loss: 0.2169 - categorical_accuracy: 0.9844 - val_loss: 0.4144 - val_categorical_accuracy: 0.9664\n",
      "Epoch 59/64\n",
      "16/16 [==============================] - 338s 22s/step - loss: 0.0835 - categorical_accuracy: 0.9883 - val_loss: 0.6298 - val_categorical_accuracy: 0.9509\n",
      "Epoch 60/64\n",
      "16/16 [==============================] - 293s 19s/step - loss: 0.0632 - categorical_accuracy: 0.9902 - val_loss: 0.3651 - val_categorical_accuracy: 0.9594\n",
      "Epoch 61/64\n",
      "16/16 [==============================] - 289s 19s/step - loss: 0.0707 - categorical_accuracy: 0.9922 - val_loss: 0.6283 - val_categorical_accuracy: 0.9504\n",
      "Epoch 62/64\n",
      "16/16 [==============================] - 216s 14s/step - loss: 0.0786 - categorical_accuracy: 0.9941 - val_loss: 0.3965 - val_categorical_accuracy: 0.9594\n",
      "Epoch 63/64\n",
      "16/16 [==============================] - 211s 14s/step - loss: 0.0148 - categorical_accuracy: 0.9959 - val_loss: 0.6080 - val_categorical_accuracy: 0.9576\n",
      "Epoch 64/64\n",
      "16/16 [==============================] - 214s 14s/step - loss: 0.1270 - categorical_accuracy: 0.9941 - val_loss: 0.2332 - val_categorical_accuracy: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118d5ad9f40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(img_generator_flow_train, \n",
    "          validation_data=img_generator_flow_valid, \n",
    "          steps_per_epoch=16, epochs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84deaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Signmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8622ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Signmodel2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ecb21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
